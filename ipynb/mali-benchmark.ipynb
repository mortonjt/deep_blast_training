{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from deepblast.trainer import LightningAligner\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from deepblast.dataset.utils import states2edges\n",
    "from deepblast.score import (alignment_score, score_local_identity, \n",
    "                             roc_edges_kernel_identity, alignment_score_kernel,\n",
    "                             score_global_alignment, score_local_alignment\n",
    "                            )\n",
    "from scipy.stats import sem\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 590M\r\n",
      "-rw-r--r-- 1 juermieboop juermieboop 590M Aug 18 12:15 'epoch=6.ckpt'\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lhrt ../lightning_logs/version_174156/checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Have the pretrained model be downloadable\n",
    "\n",
    "TODO: Have the malisam and malidup datasets downloadable as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ckpt_path = '../../deep_blast_training/lightning_logs/version_174156/checkpoints/epoch=6.ckpt'\n",
    "ckpt_path = '../../deep_blast_training/lightning_logs/version_174137/checkpoints/epoch=9.ckpt'\n",
    "\n",
    "model = LightningAligner.load_from_checkpoint(ckpt_path).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepblast.dataset.parse_mali import read_mali, read_mali_mammoth\n",
    "\n",
    "import seaborn as sns\n",
    "from deepblast.dataset.utils import states2matrix\n",
    "from deepblast.dataset.utils import state_f, tmstate_f, revstate_f\n",
    "from deepblast.score import alignment_score_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import pairwise2\n",
    "from Bio.pairwise2 import format_alignment\n",
    "from Bio.SubsMat import MatrixInfo as matlist\n",
    "from deepblast.dataset.utils import state_f\n",
    "matrix = matlist.blosum62\n",
    "def nw_f(x, y):\n",
    "    alignments = pairwise2.align.globaldx(x, y, matrix)\n",
    "    states = list(map(state_f, zip(list(alignments[0].seqA), list(alignments[0].seqB))))\n",
    "    states = ''.join(list(map(revstate_f, states)))\n",
    "    return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "malidup_root = '../data/structure_benchmarks/malidup'\n",
    "malisam_root = '../data/structure_benchmarks/malisam'\n",
    "\n",
    "mammoth_dup_root = '../data/structure_benchmarks/mammoth/malidup'\n",
    "mammoth_sam_root = '../data/structure_benchmarks/mammoth/malisam'\n",
    "\n",
    "mali_root = malisam_root\n",
    "mali_mammoth = mammoth_sam_root\n",
    "benchmark = 'malisam'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Malidup / Malisam benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in manual and Mammoth\n",
    "mammoth = read_mali_mammoth(mali_mammoth, report_ids=True)\n",
    "manual = read_mali(mali_root, tool='manual', report_ids=True)\n",
    "res = pd.merge(manual, mammoth, left_on='dir', right_on='pdb')\n",
    "res = res[['0_x', '1_x', '2_x', '2_y']]\n",
    "res = res.rename(columns={'0_x' : 0, '1_x' : 1, '2_x' : 'manual', '2_y': 'mammoth'})\n",
    "res = res[~res.set_index([0, 1]).index.duplicated(keep='first')]\n",
    "res = res.set_index([0, 1])\n",
    "\n",
    "# read in TMalign, Fast and Dali \n",
    "fast   = read_mali(mali_root, tool='fast')\n",
    "tm     = read_mali(mali_root, tool='tm')\n",
    "dali   = read_mali(mali_root, tool='dali')\n",
    "fast = fast[~fast.set_index([0, 1]).index.duplicated(keep='first')]\n",
    "tm = tm[~tm.set_index([0, 1]).index.duplicated(keep='first')]\n",
    "dali = dali[~dali.set_index([0, 1]).index.duplicated(keep='first')]\n",
    "\n",
    "# build multi-indexes\n",
    "tm_ = tm.set_index([0, 1]).rename(columns={2: 'tm'})\n",
    "fast_ = fast.set_index([0, 1]).rename(columns={2: 'fast'})\n",
    "dali_ = dali.set_index([0, 1]).rename(columns={2: 'dali'})\n",
    "\n",
    "# merge together\n",
    "res = pd.merge(res, fast_, left_index=True, right_index=True)\n",
    "res = pd.merge(res, tm_, left_index=True, right_index=True)\n",
    "res = pd.merge(res, dali_, left_index=True, right_index=True)\n",
    "#res = rename ['fast', 'tm', 'dali']\n",
    "\n",
    "# Needleman-wunsch and deepblast\n",
    "nw     = res.reset_index().apply(lambda x: nw_f(x[0], x[1]), axis=1)\n",
    "dp     = res.reset_index().apply(lambda x: model.align(x[1], x[0]), axis=1)\n",
    "res['needleman-wunsch'] = nw.values\n",
    "res['deepblast'] = dp.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'None of [0, 1] are in the columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2b9539589d0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Saving the alignment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmanual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmanual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanual\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pdb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'malisam_alignments.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   4301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4302\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4303\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of {missing} are in the columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'None of [0, 1] are in the columns'"
     ]
    }
   ],
   "source": [
    "# Saving the alignment\n",
    "manual = manual.set_index([0, 1])\n",
    "pd.merge(manual[['pdb', 'dir']], res, left_index=True, right_index=True).to_csv('malisam_alignments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse BLAST and HMMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blast and HMMER\n",
    "from deepblast.dataset.parse_hmmer import get_hmmer_alignments\n",
    "from deepblast.dataset.parse_blast import get_blast_alignments\n",
    "\n",
    "hmmer_path = f'../results/hmmer/{benchmark}-hmm.out'\n",
    "blast_path = f'../results/blast/{benchmark}_blast_alignments.xml'\n",
    "\n",
    "hmmer_df = get_hmmer_alignments(hmmer_path, mali_root)\n",
    "blast_df = get_blast_alignments(blast_path, mali_root)\n",
    "\n",
    "ref = read_mali(mali_root, tool='manual', report_ids=True)\n",
    "ref = ref.set_index(['query_id', 'hit_id'])\n",
    "\n",
    "ref_hmmer = pd.merge(ref, hmmer_df.set_index(['query_id', 'hit_id']), \n",
    "                     left_index=True, right_index=True, how='left')\n",
    "ref_hmmer = ref_hmmer.rename(columns={2: 'manual'})\n",
    "ref_blast = pd.merge(ref, blast_df.set_index(['query_id', 'hit_id']), \n",
    "                     left_index=True, right_index=True, how='left')\n",
    "ref_blast = ref_blast.rename(columns={2: 'manual'})\n",
    "\n",
    "# clean up types\n",
    "\n",
    "ref_blast = ref_blast.fillna(-1)\n",
    "ref_blast['query_start'] = ref_blast['query_start'].astype(np.int64)\n",
    "ref_blast['hit_start'] = ref_blast['hit_start'].astype(np.int64)\n",
    "\n",
    "ref_hmmer = ref_hmmer.fillna(-1)\n",
    "ref_hmmer['query_start'] = ref_hmmer['query_start'].astype(np.int64)\n",
    "ref_hmmer['hit_start'] = ref_hmmer['hit_start'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are some shit mammoth alignments, filter those out\n",
    "idx = res['mammoth'].apply(len) > 0\n",
    "res = res.loc[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define scoring functions with predefined kernels, and parallelize with Dask."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "def filter_gaps(states, edges):\n",
    "    data = zip(states, edges)\n",
    "    data = filter(lambda x: x[0] == 1, data)\n",
    "    _, edges = zip(*list(data))\n",
    "    return list(edges)\n",
    "\n",
    "\n",
    "def alignment_score_kernel(true_states: str, pred_states: str,\n",
    "                           kernel_widths: list,\n",
    "                           query_offset: int = 0, hit_offset: int = 0,\n",
    "                           no_gaps=True):\n",
    "    \"\"\" Computes ROC statistics on alignment.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    true_states : str\n",
    "        Ground truth state string\n",
    "    pred_states : str\n",
    "        Predicted state string\n",
    "    \"\"\"\n",
    "    assert len(pred_states) > 0, pred_states\n",
    "    pred_states = list(map(tmstate_f, pred_states))\n",
    "    assert len(pred_states) > 0, pred_states\n",
    "    true_states = list(map(tmstate_f, true_states))\n",
    "    pred_edges = states2edges(pred_states)\n",
    "    true_edges = states2edges(true_states)\n",
    "    # add offset to account for local alignments\n",
    "    true_edges = list(map(tuple, np.array(true_edges)))\n",
    "    pred_edges = np.array(pred_edges)\n",
    "    pred_edges[:, 0] += query_offset\n",
    "    pred_edges[:, 1] += hit_offset\n",
    "    pred_edges = list(map(tuple, pred_edges))\n",
    "    if no_gaps:\n",
    "        assert 1 in pred_states, pred_states\n",
    "        pred_edges = filter_gaps(pred_states, pred_edges)\n",
    "        true_edges = filter_gaps(true_states, true_edges)\n",
    "\n",
    "    res = []\n",
    "    for k in kernel_widths:\n",
    "        r = roc_edges_kernel_identity(true_edges, pred_edges, k)\n",
    "        res.append(r)\n",
    "    return res\n",
    "\n",
    "def score_local_identity(x, k):\n",
    "    if x['query_start'] < 0 :\n",
    "        return [0.] * len(k)\n",
    "    else:\n",
    "        return alignment_score_kernel(x['manual'], x['aln'], kernel_widths=k, \n",
    "                                      query_offset=x['query_start'],\n",
    "                                      hit_offset=x['hit_start'])\n",
    "\n",
    "def score_local_alignment(df, k, n_cores=4):\n",
    "    df2 = dd.from_pandas(df, npartitions=n_cores)\n",
    "    func = lambda x: score_local_identity(x, k)\n",
    "    res = df2.apply(func, axis=1)\n",
    "    resdf = res.compute(scheduler='processes')\n",
    "    return pd.DataFrame(list(resdf.values), columns=k)\n",
    "\n",
    "def score_global_alignment(df, col, k, n_cores=4):\n",
    "    df2 = dd.from_pandas(df, npartitions=n_cores)\n",
    "    func = lambda x: alignment_score_kernel(x['manual'], x[col], k)\n",
    "    res = df2.apply(func, axis=1)\n",
    "    resdf = res.compute(scheduler='processes')\n",
    "    return pd.DataFrame(list(resdf.values), columns=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain local and global alignment stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "k = [1, 3, 5, 10]\n",
    "\n",
    "# Obtain local alignment stats in parallel\n",
    "blast_stats = score_local_alignment(ref_blast.reset_index(), k, n_cores=30)\n",
    "hmmer_stats = score_local_alignment(ref_hmmer.reset_index(), k, n_cores=30)\n",
    "\n",
    "# Global alignments\n",
    "fast_stats = score_global_alignment(res.reset_index(), 'fast', k, n_cores=30)\n",
    "tm_stats = score_global_alignment(res.reset_index(), 'tm', k, n_cores=30)\n",
    "dali_stats = score_global_alignment(res.reset_index(), 'dali', k, n_cores=30)\n",
    "deep_stats = score_global_alignment(res.reset_index(), 'deepblast', k, n_cores=30)\n",
    "nw_stats = score_global_alignment(res.reset_index(), 'needleman-wunsch', k, n_cores=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mam_stats = score_global_alignment(res.reset_index(), 'mammoth', k, n_cores=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform some dataset massaging to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_stats['tool'] = 'fast'\n",
    "tm_stats['tool'] = 'tm'\n",
    "dali_stats['tool'] = 'dali'\n",
    "deep_stats['tool'] = 'deepblast'\n",
    "nw_stats['tool'] = 'nw'\n",
    "blast_stats['tool'] = 'blast'\n",
    "hmmer_stats['tool'] = 'hmmer'\n",
    "mam_stats['tool'] = 'mammoth'\n",
    "\n",
    "\n",
    "# add additional metadata regarding the pdb files\n",
    "manual = read_mali(mali_root, tool='manual', report_ids=True)\n",
    "fast_stats['pdb'] = manual['pdb']\n",
    "tm_stats['pdb'] = manual['pdb']\n",
    "dali_stats['pdb'] = manual['pdb']\n",
    "deep_stats['pdb'] = manual['pdb']\n",
    "nw_stats['pdb'] = manual['pdb']\n",
    "blast_stats['pdb'] = manual['pdb']\n",
    "hmmer_stats['pdb'] = manual['pdb']\n",
    "mam_stats['pdb'] = manual['pdb']\n",
    "\n",
    "\n",
    "# combine stats\n",
    "data = pd.concat((fast_stats, tm_stats, dali_stats, deep_stats, nw_stats, blast_stats, hmmer_stats, mam_stats))\n",
    "\n",
    "# save file locally for later\n",
    "data.to_csv(f'{benchmark}_perc_id.csv')\n",
    "\n",
    "# melt dataframe to make it easier to plot\n",
    "data = pd.melt(data, id_vars=['tool', 'pdb'], var_name='kernel_width')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plot the benchmark results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run if need to regenerate figures from existing data\n",
    "benchmark = 'malidup'\n",
    "data = pd.read_csv('malidup_perc_id.csv', index_col=0)\n",
    "data = pd.melt(data, id_vars=['tool', 'pdb'], var_name='kernel_width')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = {'fast' : 'Fast', 'tm' : 'TM-align', 'dali' : 'Dali', \n",
    " 'mammoth': 'Mammoth-local', 'deepblast' : 'DeepBLAST', \n",
    " 'nw' : 'Needleman-Wunsch', 'blast' : 'BLAST', 'hmmer' : 'HMMER'}\n",
    "\n",
    "data['Method'] = data.apply(lambda x: lookup[x['tool']], axis=1)\n",
    "def structure_f(x):\n",
    "    return x in {'Fast', 'TM-align', 'Dali', 'Mammoth-local'}\n",
    "        \n",
    "data['Structural'] = data['Method'].apply(structure_f)\n",
    "green = sns.light_palette(\"seagreen\")\n",
    "purple = sns.dark_palette(\"blue\", reverse=True)\n",
    "fig, ax = plt.subplots()\n",
    "palette = {\n",
    "    'Fast' : '#00838f',\n",
    "    'TM-align' : '#4dd0e1',\n",
    "    'Dali' : '#4db6ac',\n",
    "    'Mammoth-local' : '#81c784',\n",
    "    'DeepBLAST': 'r',\n",
    "    'Needleman-Wunsch' : '#ad1457', \n",
    "    'BLAST' : '#6a1b9a',\n",
    "    'HMMER' : '#283593'\n",
    "}\n",
    "\n",
    "markers = {True : '^', False : 'o'}\n",
    "\n",
    "palette = sns.color_palette(\"Set3\", 8)\n",
    "sns.lineplot(data=data, x='kernel_width', y='value', hue='Method', style='Structural',\n",
    "             ax=ax,  markers=markers, palette=palette, \n",
    "             hue_order=['Fast', 'TM-align', 'Dali', 'Mammoth-local', \n",
    "                        'DeepBLAST', 'Needleman-Wunsch', 'BLAST', 'HMMER'])\n",
    "\n",
    "ax.set_ylabel('Percent Identity')\n",
    "\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "ax.set_ylabel('True Positive Rate', fontsize=18)\n",
    "ax.set_xlabel('Kernel Width', fontsize=18)\n",
    "ax.tick_params(labelsize=14)\n",
    "\n",
    "# Put a legend to the right of the current axis\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5), prop={'size': 16})\n",
    "\n",
    "for legobj in ax.legend_.legendHandles:\n",
    "    legobj.set_linewidth(5.0)\n",
    "    \n",
    "fig.savefig(f'{benchmark}.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other statistics to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "        'val_tp', 'val_fp', 'val_fn', 'val_perc_id',\n",
    "        'val_ppv', 'val_fnr', 'val_fdr'\n",
    "]\n",
    "\n",
    "fast_stats = pd.DataFrame(list(res.apply(lambda x: alignment_score(x['manual'], x['fast']), axis=1).values), \n",
    "                          columns=columns)\n",
    "tm_stats   = pd.DataFrame(list(res.apply(lambda x: alignment_score(x['manual'], x['tm']), axis=1).values), \n",
    "                          columns=columns)\n",
    "dali_stats = pd.DataFrame(list(res.apply(lambda x: alignment_score(x['manual'], x['dali']), axis=1).values), \n",
    "                          columns=columns)\n",
    "mam_stats = pd.DataFrame(list(res.apply(lambda x: alignment_score(x['manual'], x['mammoth']), axis=1).values), \n",
    "                          columns=columns)\n",
    "deep_stats = pd.DataFrame(list(res.apply(lambda x: alignment_score(x['manual'], x['deepblast']), axis=1).values), \n",
    "                          columns=columns)\n",
    "nw_stats = pd.DataFrame(list(res.apply(lambda x: alignment_score(x['manual'], x['needleman-wunsch']), axis=1).values), \n",
    "                          columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_alignment_score(x):\n",
    "    if x['aln'] == -1:\n",
    "        n_matches = np.sum(np.array(list(x['manual'])) == ':')\n",
    "        return 0, np.nan, n_matches, 0, 0, 1, 0\n",
    "    else:\n",
    "        return alignment_score(x['manual'], x['aln'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blast_stats = pd.DataFrame(list(ref_blast.apply(local_alignment_score, axis=1).values), \n",
    "                           columns=columns)\n",
    "hmmer_stats = pd.DataFrame(list(ref_hmmer.apply(local_alignment_score, axis=1).values), \n",
    "                           columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_stats['tool'] = 'Fast'\n",
    "tm_stats['tool'] = 'TM-align'\n",
    "dali_stats['tool'] = 'Dali'\n",
    "mam_stats['tool'] = 'Mammoth-local'\n",
    "deep_stats['tool'] = 'DeepBLAST'\n",
    "nw_stats['tool'] = 'Needleman-Wunsch'\n",
    "blast_stats['tool'] = 'BLAST'\n",
    "hmmer_stats['tool'] = 'HMMER'\n",
    "\n",
    "data = pd.concat((fast_stats, tm_stats, dali_stats, mam_stats, deep_stats, nw_stats, blast_stats, hmmer_stats))\n",
    "\n",
    "data.to_csv(f'{benchmark}_allstats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in locally to save time\n",
    "data = pd.read_csv(f'{benchmark}_allstats.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "data['precision'] = data.apply(lambda x: x['val_tp'] / (x['val_tp'] + x['val_fp']), axis=1)\n",
    "data['recall'] = data.apply(lambda x: x['val_tp'] / (x['val_tp'] + x['val_fn']), axis=1)\n",
    "data['f1'] = data.apply(lambda x: 2 / ((1 / (x['precision'] + 1e-6)) + (1 / (x['recall'] + 1e-6))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette(\"Set3\", 8)\n",
    "sns.boxplot(data=data, x='recall', y='tool', orient='h', palette=palette)\n",
    "locs, labels = plt.xticks()\n",
    "_ = plt.setp(labels, fontsize=16)\n",
    "\n",
    "locs, labels = plt.yticks()\n",
    "_ = plt.setp(labels, fontsize=16)\n",
    "\n",
    "plt.xlabel('Recall', fontsize=18)\n",
    "plt.ylabel('')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{benchmark}_recall.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=data, x='precision', y='tool', orient='h', palette=palette)\n",
    "locs, labels = plt.xticks()\n",
    "_ = plt.setp(labels, fontsize=16)\n",
    "\n",
    "locs, labels = plt.yticks()\n",
    "_ = plt.setp(labels, fontsize=16)\n",
    "\n",
    "plt.xlabel('Precision', fontsize=18)\n",
    "plt.ylabel('')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{benchmark}_precision.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=data, x='f1', y='tool', orient='h', palette=palette)\n",
    "locs, labels = plt.xticks()\n",
    "_ = plt.setp(labels, fontsize=16)\n",
    "\n",
    "locs, labels = plt.yticks()\n",
    "_ = plt.setp(labels, fontsize=16)\n",
    "\n",
    "plt.xlabel('F1 score', fontsize=18)\n",
    "plt.ylabel('')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{benchmark}_f1_score.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green = sns.light_palette(\"seagreen\")\n",
    "purple = sns.dark_palette(\"blue\", reverse=True)\n",
    "fig, ax = plt.subplots()\n",
    "palette = {\n",
    "    'fast' : '#00838f',\n",
    "    'tm' : '#4dd0e1',\n",
    "    'dali' : '#4db6ac',\n",
    "    'mammoth' : '#81c784',\n",
    "    'deepblast': 'r',\n",
    "    'nw' : '#ad1457', \n",
    "    'blast' : '#6a1b9a',\n",
    "    'hmmer' : '#283593'\n",
    "}\n",
    "sns.lineplot(data=data, x='precision', y='recall', hue='tool', ax=ax,\n",
    "             palette=palette, hue_order=['fast', 'tm', 'dali', 'mammoth', 'deepblast', 'nw'])\n",
    "\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "# Put a legend to the right of the current axis\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "fig.savefig(f'{benchmark}_pr_curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.groupby(['tool']).mean()['f1'].to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.groupby(['tool']).agg(sem)['f1'].to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.groupby(['tool']).mean()['precision'].to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.groupby(['tool']).agg(sem)['precision'].to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.groupby(['tool']).mean()['recall'].to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.groupby(['tool']).agg(sem)['recall'].to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other scratch work"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def roc_edges_kernel_identity(true_edges, pred_edges, kernel_width):\n",
    "    pe_ = pred_edges\n",
    "    pe = np.array(pred_edges)\n",
    "    for k in range(kernel_width):\n",
    "        pred_edges_k_pos = pe + k\n",
    "        pred_edges_k_neg = pe - k\n",
    "        pe_ += list(map(tuple, pred_edges_k_pos))\n",
    "        pe_ += list(map(tuple, pred_edges_k_neg))\n",
    "\n",
    "    truth = set(true_edges)\n",
    "    pred = set(pe_)\n",
    "    tp = len(truth & pred)\n",
    "    perc_id = tp / len(true_edges)\n",
    "    return perc_id\n",
    "\n",
    "\n",
    "def alignment_score_kernel(true_states: str, pred_states: str, kernel_widths : list,\n",
    "                           query_offset : int = 0, hit_offset : int = 0):\n",
    "    \"\"\"\n",
    "    Computes ROC statistics on alignment\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    true_states : str\n",
    "        Ground truth state string\n",
    "    pred_states : str\n",
    "        Predicted state string\n",
    "    \"\"\"\n",
    "\n",
    "    pred_states = list(map(tmstate_f, pred_states))\n",
    "    true_states = list(map(tmstate_f, true_states))\n",
    "    pred_edges = states2edges(pred_states)\n",
    "    true_edges = states2edges(true_states)\n",
    "    # add offset to account for local alignments\n",
    "    true_edges = list(map(tuple, np.array(true_edges)))\n",
    "    pred_edges = np.array(pred_edges)\n",
    "    pred_edges[:, 0] += query_offset\n",
    "    pred_edges[:, 1] += hit_offset\n",
    "    pred_edges = list(map(tuple, pred_edges))\n",
    "\n",
    "    res = []\n",
    "    for k in kernel_widths:\n",
    "        r = roc_edges_kernel_identity(true_edges, pred_edges, k)\n",
    "        res.append(r)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "        'val_tp', 'val_fp', 'val_fn', 'val_perc_id',\n",
    "        'val_ppv', 'val_fnr', 'val_fdr'\n",
    "]\n",
    "\n",
    "fast_stats = pd.DataFrame(list(res.apply(lambda x: alignment_score(x['manual'], x['fast']), axis=1).values), \n",
    "                          columns=columns)\n",
    "tm_stats   = pd.DataFrame(list(res.apply(lambda x: alignment_score(x['manual'], x['tm']), axis=1).values), \n",
    "                          columns=columns)\n",
    "dali_stats = pd.DataFrame(list(res.apply(lambda x: alignment_score(x['manual'], x['dali']), axis=1).values), \n",
    "                          columns=columns)\n",
    "deep_stats = pd.DataFrame(list(res.apply(lambda x: alignment_score(x['manual'], x['deepblast']), axis=1).values), \n",
    "                          columns=columns)\n",
    "nw_stats = pd.DataFrame(list(res.apply(lambda x: alignment_score(x['manual'], x['needleman-wunsch']), axis=1).values), \n",
    "                          columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.distplot(fast_stats['val_perc_id'], label='fast')\n",
    "sns.distplot(tm_stats['val_perc_id'], label='tm')\n",
    "sns.distplot(dali_stats['val_perc_id'], label='dali')\n",
    "sns.distplot(deep_stats['val_perc_id'], label='deepblast')  # meh\n",
    "sns.distplot(nw_stats['val_perc_id'], label='needleman-wunsch')  # meh\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(deep_stats['val_perc_id'], label='deepblast')\n",
    "sns.distplot(nw_stats['val_perc_id'], label='needleman-wunsch')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_df = pd.DataFrame({\n",
    "    'fast': fast_stats['val_perc_id'],\n",
    "    'tm': dali_stats['val_perc_id'],\n",
    "    'dali': tm_stats['val_perc_id'],\n",
    "    'deepblast': deep_stats['val_perc_id'],\n",
    "    'nw': nw_stats['val_perc_id']\n",
    "\n",
    "})\n",
    "box_df = box_df.melt(var_name='tool', value_name='perc_id')\n",
    "sns.boxplot(x='tool', y='perc_id', data=box_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percent identity vs kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_stats['tool'] = 'fast'\n",
    "tm_stats['tool'] = 'tm'\n",
    "dali_stats['tool'] = 'dali'\n",
    "deep_stats['tool'] = 'deepblast'\n",
    "nw_stats['tool'] = 'nw'\n",
    "data = pd.concat((fast_stats, tm_stats, dali_stats, deep_stats, nw_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.melt(data, id_vars=['tool'], var_name='kernel_width')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=data, x='kernel_width', y='value', hue='tool') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('malidup_perc_id.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.lineplot(data=data, x='kernel_width', y='value', hue='tool', ax=ax)\n",
    "\n",
    "ax.set_ylabel('Percent Identity')\n",
    "\n",
    "# Shrink current axis by 20%\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "# Put a legend to the right of the current axis\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Malisam benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual = read_mali(malisam_root, tool='manual')\n",
    "fast   = read_mali(malisam_root, tool='fast')\n",
    "tm     = read_mali(malisam_root, tool='tm')\n",
    "dali   = read_mali(malisam_root, tool='dali')\n",
    "\n",
    "manual = manual[~manual.set_index([0, 1]).index.duplicated(keep='first')]\n",
    "fast = fast[~fast.set_index([0, 1]).index.duplicated(keep='first')]\n",
    "tm = tm[~tm.set_index([0, 1]).index.duplicated(keep='first')]\n",
    "dali = dali[~dali.set_index([0, 1]).index.duplicated(keep='first')]\n",
    "\n",
    "# build multi-indexes\n",
    "manual_ = manual.set_index([0, 1])\n",
    "tm_ = tm.set_index([0, 1])\n",
    "fast_ = fast.set_index([0, 1])\n",
    "dali_ = dali.set_index([0, 1])\n",
    "\n",
    "# merge together\n",
    "res = pd.merge(manual_, fast_, left_index=True, right_index=True)\n",
    "res = pd.merge(res, tm_, left_index=True, right_index=True)\n",
    "res = pd.merge(res, dali_, left_index=True, right_index=True)\n",
    "res.columns = ['manual', 'fast', 'tm', 'dali']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nw     = manual_.loc[res.index].reset_index().apply(lambda x: nw_f(x[1], x[0]), axis=1)\n",
    "dp     = manual.apply(lambda x: model.align(x[1], x[0])[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build multi-indexes\n",
    "manual = manual.set_index([0, 1])\n",
    "tm = tm.set_index([0, 1])\n",
    "fast = fast.set_index([0, 1])\n",
    "dali = dali.set_index([0, 1])\n",
    "tm = tm[~tm.index.duplicated(keep='first')]\n",
    "\n",
    "# merge together\n",
    "res = pd.merge(manual, fast, left_index=True, right_index=True)\n",
    "res = pd.merge(res, tm, left_index=True, right_index=True)\n",
    "res = pd.merge(res, dali, left_index=True, right_index=True)\n",
    "res.columns = ['manual', 'fast', 'tm', 'dali']\n",
    "res = res.dropna()\n",
    "res['needleman-wunsch'] = nw.values\n",
    "res['deepblast'] = dp.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepblast.score import alignment_score\n",
    "columns = [\n",
    "        'val_tp', 'val_fp', 'val_fn', 'val_perc_id',\n",
    "        'val_ppv', 'val_fnr', 'val_fdr'\n",
    "]\n",
    "    \n",
    "fast_stats = pd.DataFrame(list(res.apply(lambda x: alignment_score(x['manual'], x['fast']), axis=1).values), \n",
    "                          columns=columns)\n",
    "tm_stats   = pd.DataFrame(list(res.apply(lambda x: alignment_score(x['manual'], x['tm']), axis=1).values), \n",
    "                          columns=columns)\n",
    "dali_stats = pd.DataFrame(list(res.apply(lambda x: alignment_score(x['manual'], x['dali']), axis=1).values), \n",
    "                          columns=columns)\n",
    "deep_stats = pd.DataFrame(list(res.apply(lambda x: alignment_score(x['manual'], x['deepblast']), axis=1).values), \n",
    "                          columns=columns)\n",
    "nw_stats = pd.DataFrame(list(res.apply(lambda x: alignment_score(x['manual'], x['needleman-wunsch']), axis=1).values), \n",
    "                          columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(fast_stats['val_perc_id'], label='fast')\n",
    "sns.distplot(tm_stats['val_perc_id'], label='tm')\n",
    "sns.distplot(dali_stats['val_perc_id'], label='dali')\n",
    "sns.distplot(deep_stats['val_perc_id'], label='deepblast')  # meh\n",
    "sns.distplot(nw_stats['val_perc_id'], label='needleman-wunsch')  # meh\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(deep_stats['val_perc_id'], label='deepblast')\n",
    "sns.distplot(nw_stats['val_perc_id'], label='needleman-wunsch')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_df = pd.DataFrame({\n",
    "    'fast': fast_stats['val_perc_id'],\n",
    "    'tm': dali_stats['val_perc_id'],\n",
    "    'dali': tm_stats['val_perc_id'],\n",
    "    'deepblast': deep_stats['val_perc_id'],\n",
    "    'nw': nw_stats['val_perc_id']\n",
    "\n",
    "})\n",
    "box_df = box_df.melt(var_name='tool', value_name='perc_id')\n",
    "sns.boxplot(x='tool', y='perc_id', data=box_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(dali_stats['val_fdr'], dali_stats['val_fnr'], label='dali')\n",
    "plt.scatter(tm_stats['val_fdr'], tm_stats['val_fnr'], label='tm')\n",
    "plt.scatter(fast_stats['val_fdr'], fast_stats['val_fnr'], label='fast')\n",
    "plt.scatter(deep_stats['val_fdr'], deep_stats['val_fnr'], label='deepblast')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('FDR')\n",
    "plt.ylabel('FNR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "x = res.index[i]\n",
    "pred, A = model.align(x[1], x[0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "truth = res.iloc[i]['manual']\n",
    "\n",
    "columns = [\n",
    "        'val_tp', 'val_fp', 'val_fn', 'val_perc_id',\n",
    "        'val_ppv', 'val_fnr', 'val_fdr'\n",
    "]\n",
    "print(pd.Series(alignment_score(truth, pred), index=columns))\n",
    "\n",
    "sns.heatmap(states2matrix(list(map(tmstate_f, truth))), ax=ax[0])\n",
    "sns.heatmap(states2matrix(list(map(tmstate_f, pred))), ax=ax[1])\n",
    "sns.heatmap(A.cpu().detach().numpy().squeeze(), ax=ax[2], robust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepblast.dataset.utils import states2alignment\n",
    "a, b = states2alignment(np.array(list(map(tmstate_f, truth))), x[1], x[0])\n",
    "print('Ground Truth')\n",
    "print(a)\n",
    "print(b)\n",
    "a, b = states2alignment(np.array(list(map(tmstate_f, pred))), x[1], x[0])\n",
    "print('Prediction')\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "        'val_tp', 'val_fp', 'val_fn', 'val_perc_id',\n",
    "        'val_ppv', 'val_fnr', 'val_fdr'\n",
    "]\n",
    "\n",
    "print(pd.Series(alignment_score(truth, pred), index=columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(deep_stats['val_perc_id'], label='deepblast')\n",
    "sns.distplot(nw_stats['val_perc_id'], label='needleman-wunsch')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(nw_stats['val_perc_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
